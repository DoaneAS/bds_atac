## Get hostname with the following command: 
## $ hostname -f
##
## Configure environment per hostname:
## [hostname1]
## ...
##
## Use the same environment for multiple hostnames:
## [hostname2, hostname3, ...]
## ...
##
## Using alias
## [hostname1, hostname2, ... : alias]
## [alias]
## ...
##
## Using an asterisk in hostnames (IMPORTANT: only one * is allowed in hostnames)
##
## [host*name1]
##
## [*hostname2, hostname3*]


# Stanford Kundaje group clusters
[nandi, vayu, kali, amold, wotan, kadru, surya]
conda_env     = bds_atac
conda_env_py3 = bds_atac_py3
species_file = $script_dir/species/kundaje.conf
unlimited_mem_wt = true # unlimited max. memory and walltime on Kundaje clusters


# Kundaje clusters with low process priority
[mitra, durga]
conda_env     = bds_atac
conda_env_py3 = bds_atac_py3
species_file = $script_dir/species/kundaje.conf
unlimited_mem_wt = true # unlimited max. memory and walltime on Kundaje clusters
nice = 19		# low process priority
#system = sge 		# force to use SGE (Sun Grid Engine)


# Stanford SCG3
[scg*.stanford.edu, scg*.local, carmack.stanford.edu, crick.stanford.edu]
conda_env     = bds_atac
conda_env_py3 = bds_atac_py3
species_file = $script_dir/species/scg.conf
nth = 16		# number of threads for each pipeline
wt = 23:59:00		# To get queued on SCG3/4 standard (short) queue
system = sge 		# force to use SGE (Sun Grid Engine) on SCG3/4 even though a user doesn't explicitly specify SGE on command line with 'bds -s sge atac.bds ...'
retrial = 1             # number of retrial for failed tasks (SCG queue master kills tasks very frequently according to node's available resources)


# Stanford Sherlock clusters
[sherlock*.stanford.edu, sh-*.local]
conda_env     = bds_atac
conda_env_py3 = bds_atac_py3
species_file = $script_dir/species/sherlock.conf
nth = 16                # number of threads for each pipeline
wt = 46:59:00
system = slurm
retrial = 1             # number of retrial for failed tasks


# default
[default]
conda_env     = bds_atac
conda_env_py3 = bds_atac_py3

